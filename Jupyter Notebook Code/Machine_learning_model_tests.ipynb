{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3828b31f",
   "metadata": {},
   "source": [
    "# Various models were tested prior to selecting the one for inclusion in the final code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0256d2",
   "metadata": {},
   "source": [
    "### The training data was read into the script for use with all the potential training models.  Basic data manipulation was completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e3ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import initial needed libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fab85dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in training data\n",
    "file = 'winequality_training_data2.csv'\n",
    "wine_df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a4d77de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleanup data\n",
    "wine_df = wine_df.dropna()\n",
    "\n",
    "#drop any null columns\n",
    "wine_df = wine_df.dropna(axis='columns', how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee48ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional dataframe manimpulation to convert string values for wine colors to integers\n",
    "wine_df = pd.get_dummies(wine_df, columns=['color'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12467ea",
   "metadata": {},
   "source": [
    "## Tested using RandomOverSampler with the LogisticRegression model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d3cf7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({8: 15, 7: 15, 3: 15, 6: 15, 5: 15, 4: 15, 9: 15})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import needed libraries\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#split up the data\n",
    "X = wine_df.copy()\n",
    "X = X.drop(columns='quality')\n",
    "y = wine_df['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13cfa765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\purvi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#build model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a483cf8",
   "metadata": {},
   "source": [
    "#### Right away it would appear that the dataset that we were using was too large for successful usage of this model.  Continued with testing the model to verify its appropriateness or lack thereof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a664c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create predictions\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b38e52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2571428571428572"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use balanced accuracy score to assess accuracy\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239f0a33",
   "metadata": {},
   "source": [
    "#### The accuracy score provided was far below acceptable levels for this project.  Continued with further testing of other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff9851f",
   "metadata": {},
   "source": [
    "## Testing LogisticRegression without utilizing RandomOverSampling.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b84d31e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\purvi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609bf920",
   "metadata": {},
   "source": [
    "#### Received the size warning/error message again.  Again decided to contine with testing the model to verify appropriateness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cc96478",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create predictions\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5875f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17142857142857143"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5205e8f",
   "metadata": {},
   "source": [
    "#### Resulting accuracy score was lower than the previous sampling method thereby ruling out the potential use of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a7a59b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19999999999999998"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using alternate tester to see if accuracy was impacted\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38238aa6",
   "metadata": {},
   "source": [
    "#### Accuracy improved, but not to a level that provided acceptable results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d473394a",
   "metadata": {},
   "source": [
    "## Attempted using three different classifier models; Balanced Random Forest Classifier and Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "381342cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5142857142857143"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "rf_model = BalancedRandomForestClassifier()\n",
    "rf_model = rf_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = rf_model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce64b241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34285714285714286"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = EasyEnsembleClassifier()\n",
    "rf_model = rf_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = rf_model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac3e76eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4857142857142857"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#randomforestclassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model = rf_model.fit(X_train, y_train)\n",
    "\n",
    "predictions = rf_model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe0f30ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.13028499228574295, 'alcohol'),\n",
       " (0.11330455847690797, 'volatile acidity'),\n",
       " (0.097964373549354, 'sulphates'),\n",
       " (0.09171173847840954, 'fixed acidity'),\n",
       " (0.08576428758067721, 'density'),\n",
       " (0.08273137785403284, 'citric acid'),\n",
       " (0.08264824067394522, 'total sulfur dioxide'),\n",
       " (0.08194449524933392, 'chlorides'),\n",
       " (0.07958165705862494, 'pH'),\n",
       " (0.07300951037238344, 'free sulfur dioxide'),\n",
       " (0.06829818960975703, 'residual sugar'),\n",
       " (0.007507464123517582, 'color_red'),\n",
       " (0.005249114687313327, 'color_white')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = rf_model.feature_importances_\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcd1ad3",
   "metadata": {},
   "source": [
    "#### Upon first running these models, the increased results seemed very promising.  However, after further consideration, it was determined that the models were not the correct ones to use as we were trying to predict quality scores for wines which was a continuous number, not a dichotomous classification.  The resulting values were misleading and not applicable to our goal so these models were not further considered. The weighted importance of the features did provide some useful insight, however."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189dc90e",
   "metadata": {},
   "source": [
    "## After conferring with group members and others, it was determined that the problem was more of a regression concern.  Attempted to solve the concern with a multiple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "928d3df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import additional library\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#set up features to be used in model\n",
    "X = wine_df[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'color_red', 'color_white']]\n",
    "y = wine_df['quality']\n",
    "\n",
    "#build linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "#fit the training data to model\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27bbcb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.5612103200433789\n"
     ]
    }
   ],
   "source": [
    "#calculate accuracy score\n",
    "score = model.score(X, y)\n",
    "print(f'R2 Score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bfc82e",
   "metadata": {},
   "source": [
    "#### Typically an R2 score of 70 or higher is desirable for an \"acceptable\" level of accuracy.  This was still determined to be the best possible outcome and option for predicting the quality scores of our wines.  Separate sample sets were taken from the training set and were run against the model to assess predictions and the resulting scores were determined as reasonably close; most were within .3 to .6 variance based on the tested sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce5274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
